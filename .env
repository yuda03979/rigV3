# in windows, without docker write C: ..., and with docker write /c/...

# true or false
RUN_ASYNC_MODELS = true

# the max examples available in the dataset
MAX_EXAMPLES = 10000

# classification threshold - with softmax
CLASSIFICATION_THRESHOLD = 0.005
SITE_RAG_THRESHOLD = 0.005

# examples rag threshold - without softmax (must to be...)
ADD_EXAMPLE_RAG_THRESHOLD = 0.9

# if softmax. (not relevant to examples)
RAG_TEMPERATURE = 0.02



GENERATION_MODEL_NAME = "gemma-2-2b-it-Q8_0:rig"
VALIDATION_MODEL_NAME = "SmolLM2-1_7B-Instruct-Q4_K_M:rig"

#  # "Falcon3-3B-Instruct-q4_k_m:rig"

RAG_MODEL_NAME = "snowflake-arctic-embed-137m:rig"


#################################
# local comp

# the project data directory
PROJECT_DIR = "/Users/yuda/PycharmProjects/RigV3/project_dir"
EVAL_DIR = "/Users/yuda/PycharmProjects/RigV3/eval_dir"

## for the ollama container:

# ollama form models location  (NOT the gguf files!)
MODELS_DIRECTORY="/Users/yuda/PycharmProjects/RIG_v2/rig_models"

 # the gguf and modelfiles directory
GGUF_AND_MODELFILE_LOCATION="/Users/yuda/Desktop/rig_modelfiles"

###############################
aws

# the project data directory
# PROJECT_DIR = "/home/ubuntu/rigV3/project_dir"
# EVAL_DIR = "/home/ubuntu//rigV3/eval_dir"
# MODELS_DIRECTORY="/home/ubuntu/rig_models"
# GGUF_AND_MODELFILE_LOCATION="/home/ubuntu/rig_modelfiles"


###############################
elta

