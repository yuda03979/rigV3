# Docker Compose Configuration
# This configuration sets up a multi-service environment for deploying and running the Ollama application.
# It includes the Ollama service and a supporting app service, connected via a shared network.
# Persistent data and model files are managed using defined volumes.

services:
  ollama:
    image: ollama/ollama:0.5.4
    container_name: ollama_rig
    environment:
      - OLLAMA_MAX_LOADED_MODELS=4
      - OLLAMA_NUM_PARALLEL=2
      - OLLAMA_FLASH_ATTENTION=1
      - OLLAMA_KV_CACHE_TYPE="q8_0"
    volumes:
      - ollama_data:/root/.ollama
      - ${MODELS_DIRECTORY}:/root/.ollama/models
      - ${GGUF_AND_MODELFILE_LOCATION}:/root/rig_models
    restart: unless-stopped
    healthcheck:
      # The health check ensures that the Ollama service is running and accessible.
      # It sends a request to the specified endpoint and verifies a successful response.
      test: [ "CMD", "curl", "-f", "http://localhost:11434/" ]
      interval: 5s
      timeout: 3s
      retries: 10
    networks:
      - rig_network
  app:
#    build: .
#    container_name: rig
    # The `app` service is the main application container that interacts with the Ollama service.
    # It serves as the interface for processing and evaluation tasks and communicates with Ollama over the shared network.
    image: rig
    depends_on:
      - ollama
    environment:
      - OLLAMA_HOST=http://ollama:11434
      - DOCKER=true
      - RUN_ASYNC_MODELS=${RUN_ASYNC_MODELS}
      - MAX_EXAMPLES=${MAX_EXAMPLES}
      - PROJECT_DIR=${PROJECT_DIR}
      - EVAL_DIR=${EVAL_DIR}
      - CLASSIFICATION_THRESHOLD=${CLASSIFICATION_THRESHOLD}
      - RAG_TEMPERATURE=${CLASSIFICATION_TEMPERATURE}
      - SITE_RAG_THRESHOLD=${SITE_RAG_THRESHOLD}
      - ADD_EXAMPLE_RAG_THRESHOLD=${ADD_EXAMPLE_RAG_THRESHOLD}
      - GENERATION_MODEL_NAME=${GENERATION_MODEL_NAME}
      - VALIDATION_MODEL_NAME=${VALIDATION_MODEL_NAME}
      - RAG_MODEL_NAME=${RAG_MODEL_NAME}
    ports:
      - "80:80"
    volumes:
      - ${PROJECT_DIR}:${PROJECT_DIR}
      - ${EVAL_DIR}:${EVAL_DIR}
    networks:
      - rig_network
volumes:
  # This volume stores persistent data for the Ollama service.
  # It ensures that important files, such as configurations or models, are not lost when the container restarts.
  ollama_data:
networks:
  # This network facilitates communication between the `ollama` and `app` services.
  # It provides an isolated environment to ensure that services can interact securely and reliably.
  rig_network:
    driver: bridge
